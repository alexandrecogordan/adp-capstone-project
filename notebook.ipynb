{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e844abd-5c98-44c4-9f2b-7f87e88f42ba",
   "metadata": {},
   "source": [
    "# Phase 2: Policy Document Indexing for RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cf092459",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re, unicodedata\n",
    "\n",
    "from PyPDF2 import PdfReader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14296b69-265f-429c-94e3-ab64f773304f",
   "metadata": {},
   "source": [
    "## Text Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f572a554-2433-4fc9-bcb6-0fc0b877c7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdfs(directory):\n",
    "    pdf_texts = {}\n",
    "\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.pdf'):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "\n",
    "            with open(filepath, 'rb') as file:\n",
    "                pdf_reader = PdfReader(file)\n",
    "\n",
    "                page_texts = []\n",
    "                for page in pdf_reader.pages:\n",
    "                    page_texts.append(page.extract_text())\n",
    "\n",
    "                pdf_texts[filename[:-4]] = page_texts\n",
    "\n",
    "    max_pages = max(len(pages) for pages in pdf_texts.values())\n",
    "\n",
    "    df = pd.DataFrame(columns=pdf_texts.keys(), index=[f'Page {i+1}' for i in range(max_pages)])\n",
    "\n",
    "    for filename, pages in pdf_texts.items():\n",
    "        for i, text in enumerate(pages):\n",
    "            df.at[f'Page {i+1}', filename] = text\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d183d169-35de-426c-829c-3aa62ecfcee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_reader = extract_text_from_pdfs(\"assets/benefits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ad2284-ea54-4bce-b7b9-9186ca426d5d",
   "metadata": {},
   "source": [
    "## Text Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023ce22e-576d-4f6e-a9bc-2f4c2d1f314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    if s is None:\n",
    "        return ''\n",
    "    s = unicodedata.normalize('NFC',str(s)).strip()\n",
    "    return re.sub(r\"\\s+\", \" \", s)\n",
    "\n",
    "\n",
    "def chunk_text(text, chunk_size):\n",
    "    text = normalize_text(text)\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    words = text.split(\" \")\n",
    "    return [\" \".join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "\n",
    "def build_chunks(df_long,chunk_size, doc_col, page_col, text_col):\n",
    "    rows = []\n",
    "\n",
    "    for doc_id, group in df_long.groupby(doc_col):\n",
    "        groupe_sorted = group.sort_values(page_col)\n",
    "        full_text = \" \".join([normalize_text(t) for t in groupe_sorted[text_col] if pd.notna(t) ])\n",
    "        chunks = chunk_text(full_text,chunk_size)\n",
    "        for i, ch in enumerate(chunks):\n",
    "            rows.append({\n",
    "                'doc_id' : doc_id,\n",
    "                'chunk_id' : i,\n",
    "                'n_words': len(ch.split(\" \")),\n",
    "                'text' : ch\n",
    "            })\n",
    "    return pd.DataFrame(rows, columns=['doc_id', 'chunk_id', 'n_words', 'text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1fbacf5e-139d-471a-942d-8a37e592e15b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page</th>\n",
       "      <th>document</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>TechLance Retirement Plan (401k) Policy\\nIntro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>TechLance’s matching formula is designed to re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>the contribution amounts. You can opt out of a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>Investment performance and expense ratios are ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>The 401(k) plan allows loans for participants ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   page                document  \\\n",
       "0     1  401k-retirement-policy   \n",
       "1     2  401k-retirement-policy   \n",
       "2     3  401k-retirement-policy   \n",
       "3     4  401k-retirement-policy   \n",
       "4     5  401k-retirement-policy   \n",
       "\n",
       "                                                text  \n",
       "0  TechLance Retirement Plan (401k) Policy\\nIntro...  \n",
       "1  TechLance’s matching formula is designed to re...  \n",
       "2  the contribution amounts. You can opt out of a...  \n",
       "3  Investment performance and expense ratios are ...  \n",
       "4  The 401(k) plan allows loans for participants ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_long = pdf_reader.reset_index().melt(id_vars=['index'], var_name='document', value_name='text')\n",
    "df_long = df_long.rename(columns={'index': 'page'})\n",
    "df_long['page'] = df_long['page'].str.replace('Page','').astype(int)\n",
    "\n",
    "df_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a60d895-0242-4eea-b09b-f231daac5cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>n_words</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>TechLance Retirement Plan (401k) Policy Introd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>can contribute between 1% and 100% of their sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>2</td>\n",
       "      <td>200</td>\n",
       "      <td>always 100% vested in your own contributions, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>3</td>\n",
       "      <td>200</td>\n",
       "      <td>of automatic escalation or adjust the increase...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>4</td>\n",
       "      <td>200</td>\n",
       "      <td>and small-cap funds, international developed a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>5</td>\n",
       "      <td>200</td>\n",
       "      <td>beneﬁt, but qualiﬁed withdrawals in retirement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>6</td>\n",
       "      <td>200</td>\n",
       "      <td>impact your long-term retirement savings. You ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>7</td>\n",
       "      <td>200</td>\n",
       "      <td>withdrawal penalties, and you’re suspended fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>8</td>\n",
       "      <td>200</td>\n",
       "      <td>roll it over to a new employer’s plan or indiv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>9</td>\n",
       "      <td>200</td>\n",
       "      <td>accounts, and taxable investment accounts. Cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>10</td>\n",
       "      <td>200</td>\n",
       "      <td>and summary plan descriptions that detail all ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>11</td>\n",
       "      <td>200</td>\n",
       "      <td>the TechLance plan (if balance exceeds $5,000)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>401k-retirement-policy</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>speciﬁc situation, contact HR or call the reti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>childcare-policy</td>\n",
       "      <td>0</td>\n",
       "      <td>200</td>\n",
       "      <td>TechLance Childcare Support Policy Introductio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>childcare-policy</td>\n",
       "      <td>1</td>\n",
       "      <td>200</td>\n",
       "      <td>age groups. Our on-site center provides age-ap...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    doc_id  chunk_id  n_words  \\\n",
       "0   401k-retirement-policy         0      200   \n",
       "1   401k-retirement-policy         1      200   \n",
       "2   401k-retirement-policy         2      200   \n",
       "3   401k-retirement-policy         3      200   \n",
       "4   401k-retirement-policy         4      200   \n",
       "5   401k-retirement-policy         5      200   \n",
       "6   401k-retirement-policy         6      200   \n",
       "7   401k-retirement-policy         7      200   \n",
       "8   401k-retirement-policy         8      200   \n",
       "9   401k-retirement-policy         9      200   \n",
       "10  401k-retirement-policy        10      200   \n",
       "11  401k-retirement-policy        11      200   \n",
       "12  401k-retirement-policy        12       11   \n",
       "13        childcare-policy         0      200   \n",
       "14        childcare-policy         1      200   \n",
       "\n",
       "                                                 text  \n",
       "0   TechLance Retirement Plan (401k) Policy Introd...  \n",
       "1   can contribute between 1% and 100% of their sa...  \n",
       "2   always 100% vested in your own contributions, ...  \n",
       "3   of automatic escalation or adjust the increase...  \n",
       "4   and small-cap funds, international developed a...  \n",
       "5   beneﬁt, but qualiﬁed withdrawals in retirement...  \n",
       "6   impact your long-term retirement savings. You ...  \n",
       "7   withdrawal penalties, and you’re suspended fro...  \n",
       "8   roll it over to a new employer’s plan or indiv...  \n",
       "9   accounts, and taxable investment accounts. Cre...  \n",
       "10  and summary plan descriptions that detail all ...  \n",
       "11  the TechLance plan (if balance exceeds $5,000)...  \n",
       "12  speciﬁc situation, contact HR or call the reti...  \n",
       "13  TechLance Childcare Support Policy Introductio...  \n",
       "14  age groups. Our on-site center provides age-ap...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks = build_chunks(df_long, 200, 'document', 'page', 'text')\n",
    "df_chunks.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9db15c9-9136-4bc0-b283-790f6106e1dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc_id\n",
      "401k-retirement-policy          13\n",
      "childcare-policy                11\n",
      "gym-policy                      11\n",
      "health-insurance-policy         11\n",
      "life-insurance-policy           11\n",
      "tuition-reimbursement-policy    11\n",
      "vacation-policy                 10\n",
      "work-from-home-policy           11\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check number of chunk per document \n",
    "print(df_chunks.groupby('doc_id').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a77dd8f-e083-4166-ba71-4299a49b8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Dataframe into csv file \n",
    "df_chunks.to_csv('assets/benefits/policy_chunks.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c329a3-50cc-41f7-a161-b3b57b3cfcf1",
   "metadata": {},
   "source": [
    "## Vector Store Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "082ed4ba-b365-4208-9b9e-21d823b78119",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"env.txt\")\n",
    "\n",
    "if not os.environ.get(\"OPENAI_API_KEY\"):\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb89206f-cde6-4eb3-8929-6c44d301c132",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "def build_faiss_store(chunks, metadatas):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-4-large\")\n",
    "    \n",
    "    documents = [Document(page_content=chunk, metadata=meta) for chunk, meta in zip(chunks, metadatas)]\n",
    "    \n",
    "    vectorstore = FAISS.from_documents(\n",
    "        documents=documents,\n",
    "        embedding=embeddings\n",
    "    )\n",
    "    \n",
    "    vectorstore.save_local(\"./faiss_db\")\n",
    "    \n",
    "    return vectorstore, embeddings\n",
    "\n",
    "def load_faiss_store():\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-4-large\")\n",
    "    vectorstore = FAISS.load_local(\"./faiss_db\", embeddings, allow_dangerous_deserialization=True)\n",
    "    \n",
    "    return vectorstore, embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3a13c8-04ed-480e-a5f1-af91e80c9ec5",
   "metadata": {},
   "source": [
    "## Retrieval Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fac7a0-2687-409e-a532-e217372c6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"What is the eligibility for Tuition Reimbursement?\", \n",
    "           \"What is the eligibility for Tuition Reimbursement?\",\n",
    "           \"What is the eligibility for Tuition Reimbursement?\",\n",
    "           \"What is the eligibility for Tuition Reimbursement?\",\n",
    "           \"What is the eligibility for Tuition Reimbursement?\"]\n",
    "\n",
    "for query in queries:\n",
    "    vectorstore.similarity_search(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19970201-3bb8-4dbf-afad-c2b78fac7b22",
   "metadata": {},
   "source": [
    "## Advanced RAG Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33e569c-e9a4-4156-ae12-a18ecb4fce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Metadata filtering, Content-based filtering, Query expansion, HyDE, Reranking, Hybrid search, Context Distillation, Multi-hop question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9057cfc-bc9f-40b6-9399-96d2d2a6c315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
    "\n",
    "# 1. Metadata Filtering RAG\n",
    "class MetadataFilteringRAG:\n",
    "    def __init__(self):\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma(embedding_function=self.embeddings)\n",
    "        \n",
    "    def add_documents(self, documents, metadata):\n",
    "        # Add documents with metadata to vector store\n",
    "        self.vectorstore.add_texts(documents, metadatas=metadata)\n",
    "        \n",
    "    def query(self, query, metadata_filter):\n",
    "        # Retrieve documents matching metadata filter\n",
    "        docs = self.vectorstore.similarity_search(\n",
    "            query,\n",
    "            filter=metadata_filter\n",
    "        )\n",
    "        return docs\n",
    "\n",
    "# 2. Query Expansion RAG \n",
    "class QueryExpansionRAG:\n",
    "    def __init__(self):\n",
    "        self.llm = OpenAI()\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma(embedding_function=self.embeddings)\n",
    "        \n",
    "        # Prompt for query expansion\n",
    "        expansion_template = \"\"\"Generate 3 different versions of the following query \n",
    "        that capture the same meaning but use different words:\n",
    "        Query: {query}\n",
    "        \n",
    "        Different versions:\"\"\"\n",
    "        \n",
    "        self.expansion_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=expansion_template\n",
    "        )\n",
    "        self.expansion_chain = LLMChain(llm=self.llm, prompt=self.expansion_prompt)\n",
    "        \n",
    "    def expand_query(self, query):\n",
    "        # Generate variations of the query\n",
    "        expanded = self.expansion_chain.run(query)\n",
    "        expanded_queries = [query] + expanded.strip().split(\"\\n\")\n",
    "        return expanded_queries\n",
    "    \n",
    "    def query(self, query):\n",
    "        # Get expanded queries\n",
    "        expanded_queries = self.expand_query(query)\n",
    "        \n",
    "        # Search with all query versions and combine results\n",
    "        all_docs = []\n",
    "        for q in expanded_queries:\n",
    "            docs = self.vectorstore.similarity_search(q)\n",
    "            all_docs.extend(docs)\n",
    "            \n",
    "        # Remove duplicates\n",
    "        seen = set()\n",
    "        unique_docs = []\n",
    "        for doc in all_docs:\n",
    "            if doc.page_content not in seen:\n",
    "                seen.add(doc.page_content)\n",
    "                unique_docs.append(doc)\n",
    "                \n",
    "        return unique_docs\n",
    "\n",
    "# 3. Hypothetical Document Embeddings (HyDE) RAG\n",
    "class HyDERAG:\n",
    "    def __init__(self):\n",
    "        self.llm = OpenAI()\n",
    "        self.embeddings = OpenAIEmbeddings()\n",
    "        self.vectorstore = Chroma(embedding_function=self.embeddings)\n",
    "        \n",
    "        # Prompt to generate hypothetical document\n",
    "        hyde_template = \"\"\"Given a question, write a hypothetical passage \n",
    "        that would contain the answer to the question.\n",
    "        \n",
    "        Question: {query}\n",
    "        \n",
    "        Hypothetical passage:\"\"\"\n",
    "        \n",
    "        self.hyde_prompt = PromptTemplate(\n",
    "            input_variables=[\"query\"],\n",
    "            template=hyde_template\n",
    "        )\n",
    "        self.hyde_chain = LLMChain(llm=self.llm, prompt=self.hyde_prompt)\n",
    "        \n",
    "    def generate_hypothetical_doc(self, query):\n",
    "        # Generate hypothetical document that would answer query\n",
    "        return self.hyde_chain.run(query)\n",
    "    \n",
    "    def query(self, query):\n",
    "        # Generate hypothetical document\n",
    "        hypothetical_doc = self.generate_hypothetical_doc(query)\n",
    "        \n",
    "        # Use hypothetical doc embedding to find similar real docs\n",
    "        docs = self.vectorstore.similarity_search(hypothetical_doc)\n",
    "        return docs\n",
    "\n",
    "# Example usage and testing\n",
    "def test_rag_methods():\n",
    "    # Test documents\n",
    "    documents = [\n",
    "        \"The sky is blue because of Rayleigh scattering.\",\n",
    "        \"Photosynthesis is how plants convert sunlight to energy.\",\n",
    "        \"The theory of relativity was proposed by Einstein.\"\n",
    "    ]\n",
    "    \n",
    "    metadata = [\n",
    "        {\"topic\": \"physics\", \"difficulty\": \"basic\"},\n",
    "        {\"topic\": \"biology\", \"difficulty\": \"intermediate\"}, \n",
    "        {\"topic\": \"physics\", \"difficulty\": \"advanced\"}\n",
    "    ]\n",
    "    \n",
    "    # Test metadata filtering\n",
    "    meta_rag = MetadataFilteringRAG()\n",
    "    meta_rag.add_documents(documents, metadata)\n",
    "    physics_docs = meta_rag.query(\n",
    "        \"What physics concepts?\", \n",
    "        {\"topic\": \"physics\"}\n",
    "    )\n",
    "    \n",
    "    # Test query expansion\n",
    "    expand_rag = QueryExpansionRAG()\n",
    "    expand_rag.vectorstore.add_texts(documents)\n",
    "    expanded_results = expand_rag.query(\"How do plants make food?\")\n",
    "    \n",
    "    # Test HyDE\n",
    "    hyde_rag = HyDERAG()\n",
    "    hyde_rag.vectorstore.add_texts(documents)\n",
    "    hyde_results = hyde_rag.query(\"What causes the sky's color?\")\n",
    "    \n",
    "    return physics_docs, expanded_results, hyde_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    physics_docs, expanded_results, hyde_results = test_rag_methods()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
